{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15bd6b6",
   "metadata": {},
   "source": [
    "## Introducción <a id='intro'></a>\n",
    "Como analista de datos, tu trabajo consiste en analizar datos para extraer información valiosa de ellos y tomar decisiones en consecuencia. Esto implica pasar por diferentes etapas, como la descripción general de los datos, el preprocesamiento y la prueba de hipótesis.\n",
    "\n",
    "Siempre que investiguemos, necesitamos formular hipótesis que después podamos probar. A veces, aceptaremos estas hipótesis; otras veces, las rechazaremos. Para tomar las decisiones adecuadas, una empresa debe ser capaz de entender si está haciendo las suposiciones correctas.\n",
    "\n",
    "En este proyecto, compararás las preferencias musicales de las ciudades de Springfield y Shelbyville. Estudiarás datos reales de música online para probar la hipótesis que planteamos a continuación y compararás el comportamiento de los usuarios de estas dos ciudades.\n",
    "\n",
    "### Objetivo:\n",
    "Probar la hipótesis:\n",
    "1. La actividad de los usuarios difiere según el día de la semana y dependiendo de la ciudad.\n",
    "\n",
    "\n",
    "### Etapas\n",
    "Los datos del comportamiento de los usuarios se almacenan en el archivo `/datasets/music_project_en.csv`. No hay información sobre la calidad de los datos, así que necesitarás examinarlos antes de probar la hipótesis.\n",
    "\n",
    "Primero, debes evaluar la calidad de los datos y ver si los problemas son significativos. Más tarde, durante el preprocesamiento de datos, deberás abordar los problemas más críticos.\n",
    "\n",
    "Tu proyecto contará con estas tres etapas:\n",
    " 1. Descripción de los datos.\n",
    " 2. Preprocesamiento de los datos.\n",
    " 3. Prueba de la hipótesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bccfd10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userID                        Track            artist   genre  \\\n",
      "0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n",
      "1  55204538  Delayed Because of Accident  Andreas Rönnberg    rock   \n",
      "2    20EC38            Funiculì funiculà       Mario Lanza     pop   \n",
      "3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n",
      "4  E2DC1FAE                  Soul People        Space Echo   dance   \n",
      "5  842029A1                       Chains          Obladaet  rusrap   \n",
      "6  4CB90AA5                         True      Roman Messer   dance   \n",
      "7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n",
      "8  8FA1D3BE                     L’estate       Julia Dalia  ruspop   \n",
      "9  E772D5C0                    Pessimist               NaN   dance   \n",
      "\n",
      "        City        time        Day  \n",
      "0  Shelbyville  20:28:33  Wednesday  \n",
      "1  Springfield  14:07:09     Friday  \n",
      "2  Shelbyville  20:58:07  Wednesday  \n",
      "3  Shelbyville  08:37:09     Monday  \n",
      "4  Springfield  08:34:34     Monday  \n",
      "5  Shelbyville  13:09:41     Friday  \n",
      "6  Springfield  13:00:07  Wednesday  \n",
      "7  Springfield  20:47:49  Wednesday  \n",
      "8  Springfield  09:17:40     Friday  \n",
      "9  Shelbyville  21:20:49  Wednesday  \n"
     ]
    }
   ],
   "source": [
    "# Importa pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Lee el archivo y almacénalo en df\n",
    "df = pd.read_csv('music_project_en.csv')\n",
    "\n",
    "# Obtén las 10 primeras filas de la tabla df\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d6cb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65079 entries, 0 to 65078\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0     userID  65079 non-null  object\n",
      " 1   Track     63736 non-null  object\n",
      " 2   artist    57512 non-null  object\n",
      " 3   genre     63881 non-null  object\n",
      " 4     City    65079 non-null  object\n",
      " 5   time      65079 non-null  object\n",
      " 6   Day       65079 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Obtén la información general sobre nuestros datos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8215ca8",
   "metadata": {},
   "source": [
    "Estas son nuestras observaciones sobre la tabla. Contiene siete columnas que almacenan los mismos tipos de datos: `object`.\n",
    "\n",
    "Según la documentación:\n",
    "- `' userID'`: identificador del usuario;\n",
    "- `'Track'`: título de la canción;\n",
    "- `'artist'`: nombre del artista;\n",
    "- `'genre'`: género de la canción;\n",
    "- `'City'`: ciudad del usuario;\n",
    "- `'time'`: la hora exacta en la que se reprodujo la canción;\n",
    "- `'Day'`: día de la semana.\n",
    "\n",
    "Podemos ver tres problemas con el estilo en los encabezados de la tabla:\n",
    "1. Algunos encabezados están en mayúsculas, otros en minúsculas.\n",
    "2. Hay espacios en algunos encabezados.\n",
    "3. El tercer inconveniente que se puede observar en los encabezados de la tabla es la presencia de caracteres especiales, como el apóstrofo (')\n",
    "\n",
    "### Escribe algunas observaciones por tu parte. Contesta a las siguientes preguntas: <a id='data_review_conclusions'></a>\n",
    "\n",
    "`1.   ¿Qué tipo de datos hay en las filas? ¿Cómo podemos saber qué almacenan las columnas?`\n",
    "\n",
    "`2.   ¿Hay suficientes datos para proporcionar respuestas a nuestra hipótesis o necesitamos más información?`\n",
    "\n",
    "`3.   ¿Notaste algún problema en los datos, como valores ausentes, duplicados o tipos de datos incorrectos?`\n",
    "\n",
    "1.En las filas del DataFrame, los tipos de datos son todos de tipo\n",
    "object\n",
    ", lo que indica que son cadenas de texto. Esto incluye:\n",
    "userID\n",
    ": Identificadores de usuario.\n",
    "Track\n",
    ": Títulos de las canciones.\n",
    "artist\n",
    ": Nombres de los artistas.\n",
    "genre\n",
    ": Géneros musicales.\n",
    "City\n",
    ": Ciudades de los usuarios.\n",
    "time\n",
    ": Hora de reproducción.\n",
    "Day\n",
    ": Día de la semana.\n",
    "Podemos saber qué almacenan las columnas observando los nombres de las columnas y los datos que contienen. Además, el método\n",
    "df.info()\n",
    "proporciona un resumen de los tipos de datos y la cantidad de valores no nulos en cada columna.\n",
    "\n",
    "2.La cantidad de datos parece ser considerable, con más de 65,000 entradas. Sin embargo, la suficiencia de los datos depende de la hipótesis específica que se esté investigando. Si la hipótesis se relaciona con patrones de reproducción de canciones o preferencias de género, los datos pueden ser suficientes. Sin embargo, si se requiere un análisis más detallado, como la correlación entre diferentes variables o la segmentación de usuarios, podría ser necesario obtener más información, como datos demográficos o más registros de reproducción.\n",
    "\n",
    "3.Se observan varios valores ausentes en las columnas\n",
    "Track, artist y genre\n",
    "Esto puede ser un problema si se requiere información completa para análisis posteriores. Por ejemplo:\n",
    "Track\n",
    ": 63,736 no nulos de 65,079.\n",
    "artist\n",
    ": 57,512 no nulos de 65,079.\n",
    "genre\n",
    ": 63,881 no nulos de 65,079."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99250be0",
   "metadata": {},
   "source": [
    "## Etapa 2. Preprocesamiento de los datos <a id='data_preprocessing'></a>\n",
    "\n",
    "Tu objetivo aquí es preparar los datos para analizarlos.\n",
    "El primer paso es resolver los problemas con los encabezados. Después podemos avanzar a los valores ausentes y duplicados. ¡Empecemos!\n",
    "\n",
    "Vamos a corregir el formato en los encabezados de la tabla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab7a2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Muestra los nombres de las columnas\n",
    "encabezados = df.columns\n",
    "print(encabezados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2fbdc",
   "metadata": {},
   "source": [
    "Vamos cambiar los encabezados de la tabla siguiendo las reglas estilísticas convencionales:\n",
    "*   Todos los caracteres deben ser minúsculas.\n",
    "*   Elimina los espacios.\n",
    "*   Si el nombre tiene varias palabras, utiliza snake_case.\n",
    "\n",
    "Anteriormente, aprendiste una forma automática de cambiar el nombre de las columnas. Vamos a aplicarla ahora.\n",
    "\n",
    "Utiliza el bucle for para iterar sobre los nombres de las columnas y poner todos los caracteres en minúsculas. Cuando hayas terminado, vuelve a mostrar los encabezados de la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c59a5da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cambiar los encabezados de la tabla a minúsculas utilizando un bucle for\n",
    "nuevos_encabezados = []\n",
    "for col in df.columns:\n",
    "    nuevos_encabezados.append(col.lower())\n",
    "\n",
    "# Asignar los nuevos encabezados al DataFrame\n",
    "df.columns = nuevos_encabezados\n",
    "\n",
    "# Mostrar los nuevos encabezados\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a9e59c",
   "metadata": {},
   "source": [
    "### Ahora, utilizando el mismo método, elimina los espacios al principio y al final de los nombres de las columnas y muestra los nombres de las columnas de nuevo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7cd9540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Bucle en los encabezados que elimina los espacios\n",
    "# Cambiar los encabezados de la tabla eliminando espacios al principio y al final\n",
    "nuevos_encabezados = []\n",
    "for col in df.columns:\n",
    "    nuevos_encabezados.append(col.strip())  # Eliminar espacios al principio y al final\n",
    "\n",
    "# Asignar los nuevos encabezados al DataFrame\n",
    "df.columns = nuevos_encabezados\n",
    "\n",
    "# Mostrar los nuevos encabezados\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabf622",
   "metadata": {},
   "source": [
    " ### Necesitamos aplicar la regla de snake_case en la columna `userid`. Debe ser `user_id`. Cambia el nombre de esta columna y muestra los nombres de todas las columnas cuando hayas terminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a1da7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cambia el nombre de la columna \"userid\"\n",
    "df.rename(columns={'userid': 'user_id'}, inplace=True)\n",
    "\n",
    "# Mostrar los nuevos encabezados\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1ae38",
   "metadata": {},
   "source": [
    "### Valores ausentes \n",
    "\n",
    "Primero, encuentra el número de valores ausentes en la tabla. Debes utilizar dos métodos para obtener el número de valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cafeb132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores ausentes por columna:\n",
      "user_id       0\n",
      "track      1343\n",
      "artist     7567\n",
      "genre      1198\n",
      "city          0\n",
      "time          0\n",
      "day           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calcula el número de valores ausentes\n",
    "valores_ausentes = df.isnull().sum()\n",
    "print(\"Número de valores ausentes por columna:\")\n",
    "print(valores_ausentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e09e2c",
   "metadata": {},
   "source": [
    "No todos los valores ausentes afectan de la misma forma a la investigación. Por ejemplo, los valores ausentes en 'track' y 'artist' no son cruciales para el análisis, ya que estos datos son más descriptivos que analíticos. Por eso, puedes reemplazarlos directamente con un valor predeterminado como el string 'unknown' (desconocido).\n",
    "\n",
    "En cambio, los valores ausentes en 'genre' sí pueden influir en la comparación entre las preferencias musicales de Springfield y Shelbyville. En un escenario real, lo ideal sería investigar por qué faltan estos datos e intentar recuperarlos. Pero en este proyecto no tenemos esa posibilidad, así que deberás rellenar esos valores con un valor predeterminado.\n",
    "\n",
    "Como vimos anteriormente en las lecciones, la mejor manera de hacerlo es crear una lista con los nombres de las columnas que necesitan reemplazarse.  Luego, utilizar esta lista para iterar sobre cada columna y realizar el reemplazo correspondiente.\n",
    "\n",
    "Etapa 2.6. Sustituye los valores ausentes en las columnas `'track'`, `'artist'` y `'genre'` con el string `'unknown'`.\n",
    "\n",
    "1. Crea una lista llamada columns_to_replace que contenga los nombres de las columnas 'track', 'artist' y 'genre'.\n",
    "\n",
    "2. Usa un bucle for para iterar sobre cada columna en columns_to_replace.\n",
    "\n",
    "3. Dentro del bucle, sustituye los valores ausentes en cada columna con el string `'unknown'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5957c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucle en los encabezados reemplazando los valores ausentes con 'unknown'\n",
    "# Creamos la lista de columnas que necesitan reemplazo\n",
    "columns_to_replace = ['track', 'artist', 'genre']\n",
    "\n",
    "# Iteramos sobre cada columna en la lista\n",
    "for column in columns_to_replace:\n",
    "    # Sustituimos los valores ausentes con 'unknown' y asignamos el resultado de nuevo a la columna\n",
    "    df[column] = df[column].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c68e8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    0\n",
      "track      0\n",
      "artist     0\n",
      "genre      0\n",
      "city       0\n",
      "time       0\n",
      "day        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cuenta los valores ausentes\n",
    "valores_ausentes = df.isnull().sum()\n",
    "print(valores_ausentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a25f4",
   "metadata": {},
   "source": [
    "### Duplicados \n",
    "Encuentra el número de duplicados explícitos en la tabla. Una vez más, debes aplicar dos métodos para obtener la cantidad de duplicados explícitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "057a3d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de duplicados explícitos: 3826\n"
     ]
    }
   ],
   "source": [
    "# Cuenta los duplicados explícitos\n",
    "# Contar duplicados\n",
    "num_duplicados = df.duplicated().sum()\n",
    "print(f\"Número de duplicados explícitos: {num_duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0cf58c",
   "metadata": {},
   "source": [
    "Ahora, elimina todos los duplicados. Para ello, llama al método que hace exactamente esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a27d057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id                              track            artist  \\\n",
      "0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n",
      "1      55204538        Delayed Because of Accident  Andreas Rönnberg   \n",
      "2        20EC38                  Funiculì funiculà       Mario Lanza   \n",
      "3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n",
      "4      E2DC1FAE                        Soul People        Space Echo   \n",
      "...         ...                                ...               ...   \n",
      "65074  729CBB09                            My Name            McLean   \n",
      "65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n",
      "65076  C5E3A0D5                          Jalopiina           unknown   \n",
      "65077  321D0506                      Freight Train     Chas McDevitt   \n",
      "65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n",
      "\n",
      "            genre         city      time        day  \n",
      "0            rock  Shelbyville  20:28:33  Wednesday  \n",
      "1            rock  Springfield  14:07:09     Friday  \n",
      "2             pop  Shelbyville  20:58:07  Wednesday  \n",
      "3            folk  Shelbyville  08:37:09     Monday  \n",
      "4           dance  Springfield  08:34:34     Monday  \n",
      "...           ...          ...       ...        ...  \n",
      "65074         rnb  Springfield  13:32:28  Wednesday  \n",
      "65075         hip  Shelbyville  10:00:00     Monday  \n",
      "65076  industrial  Springfield  20:09:26     Friday  \n",
      "65077        rock  Springfield  21:43:59     Friday  \n",
      "65078     country  Springfield  21:59:46     Friday  \n",
      "\n",
      "[61253 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Elimina los duplicados explícitos\n",
    "\n",
    "df_sin_duplicados = df.drop_duplicates()\n",
    "\n",
    "# Mostrar el DataFrame sin duplicados\n",
    "print(df_sin_duplicados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735df8bc",
   "metadata": {},
   "source": [
    "### Comprobemos ahora si conseguimos eliminar todos los duplicados. Cuenta los duplicados explícitos una vez más para asegurarte de haberlos eliminado todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5d336ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de duplicados después de eliminar: 0\n"
     ]
    }
   ],
   "source": [
    "# Comprueba de nuevo si hay duplicados\n",
    "duplicados_finales = df_sin_duplicados.duplicated().sum()\n",
    "print(f\"Número de duplicados después de eliminar: {duplicados_finales}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba034f",
   "metadata": {},
   "source": [
    "Ahora queremos deshacernos de los duplicados implícitos en la columna `genre`. Por ejemplo, el nombre de un género se puede escribir de varias formas. Dichos errores también pueden afectar al resultado.\n",
    "\n",
    "Etapa 2.11. Primero debemos mostrar una lista de nombres de géneros únicos, por orden alfabético. Para ello:\n",
    "1. Extrae la columna `genre` del DataFrame.\n",
    "2. Llama al método que devolverá todos los valores únicos en la columna extraída.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5839c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acid', 'acoustic', 'action', 'adult', 'africa', 'afrikaans', 'alternative', 'ambient', 'americana', 'animated', 'anime', 'arabesk', 'arabic', 'arena', 'argentinetango', 'art', 'audiobook', 'avantgarde', 'axé', 'baile', 'balkan', 'beats', 'bigroom', 'black', 'bluegrass', 'blues', 'bollywood', 'bossa', 'brazilian', 'breakbeat', 'breaks', 'broadway', 'cantautori', 'cantopop', 'canzone', 'caribbean', 'caucasian', 'celtic', 'chamber', 'children', 'chill', 'chinese', 'choral', 'christian', 'christmas', 'classical', 'classicmetal', 'club', 'colombian', 'comedy', 'conjazz', 'contemporary', 'country', 'cuban', 'dance', 'dancehall', 'dancepop', 'dark', 'death', 'deep', 'deutschrock', 'deutschspr', 'dirty', 'disco', 'dnb', 'documentary', 'downbeat', 'downtempo', 'drum', 'dub', 'dubstep', 'eastern', 'easy', 'electronic', 'electropop', 'emo', 'entehno', 'epicmetal', 'estrada', 'ethnic', 'eurofolk', 'european', 'experimental', 'extrememetal', 'fado', 'film', 'fitness', 'flamenco', 'folk', 'folklore', 'folkmetal', 'folkrock', 'folktronica', 'forró', 'frankreich', 'französisch', 'french', 'funk', 'future', 'gangsta', 'garage', 'german', 'ghazal', 'gitarre', 'glitch', 'gospel', 'gothic', 'grime', 'grunge', 'gypsy', 'handsup', \"hard'n'heavy\", 'hardcore', 'hardstyle', 'hardtechno', 'hip', 'hip-hop', 'hiphop', 'historisch', 'holiday', 'hop', 'horror', 'house', 'idm', 'independent', 'indian', 'indie', 'indipop', 'industrial', 'inspirational', 'instrumental', 'international', 'irish', 'jam', 'japanese', 'jazz', 'jewish', 'jpop', 'jungle', 'k-pop', 'karadeniz', 'karaoke', 'kayokyoku', 'korean', 'laiko', 'latin', 'latino', 'leftfield', 'local', 'lounge', 'loungeelectronic', 'lovers', 'malaysian', 'mandopop', 'marschmusik', 'meditative', 'mediterranean', 'melodic', 'metal', 'metalcore', 'mexican', 'middle', 'minimal', 'miscellaneous', 'modern', 'mood', 'mpb', 'muslim', 'native', 'neoklassik', 'neue', 'new', 'newage', 'newwave', 'nu', 'nujazz', 'numetal', 'oceania', 'old', 'opera', 'orchestral', 'other', 'piano', 'pop', 'popelectronic', 'popeurodance', 'post', 'posthardcore', 'postrock', 'power', 'progmetal', 'progressive', 'psychedelic', 'punjabi', 'punk', 'quebecois', 'ragga', 'ram', 'rancheras', 'rap', 'rave', 'reggae', 'reggaeton', 'regional', 'relax', 'religious', 'retro', 'rhythm', 'rnb', 'rnr', 'rock', 'rockabilly', 'romance', 'roots', 'ruspop', 'rusrap', 'rusrock', 'salsa', 'samba', 'schlager', 'self', 'sertanejo', 'shoegazing', 'showtunes', 'singer', 'ska', 'slow', 'smooth', 'soul', 'soulful', 'sound', 'soundtrack', 'southern', 'specialty', 'speech', 'spiritual', 'sport', 'stonerrock', 'surf', 'swing', 'synthpop', 'sängerportrait', 'tango', 'tanzorchester', 'taraftar', 'tech', 'techno', 'thrash', 'top', 'traditional', 'tradjazz', 'trance', 'tribal', 'trip', 'triphop', 'tropical', 'türk', 'türkçe', 'unknown', 'urban', 'uzbek', 'variété', 'vi', 'videogame', 'vocal', 'western', 'world', 'worldbeat', 'ïîï']\n"
     ]
    }
   ],
   "source": [
    "# Inspecciona los nombres de géneros únicos\n",
    "# Extraemos la columna 'genre'\n",
    "generos = df['genre']\n",
    "\n",
    "# Obtenemos los valores únicos y los ordenamos alfabéticamente\n",
    "generos_unicos = generos.unique()\n",
    "generos_unicos_ordenados = sorted(generos_unicos)\n",
    "\n",
    "# Mostramos la lista de géneros únicos\n",
    "print(generos_unicos_ordenados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95fd6cf",
   "metadata": {},
   "source": [
    "Vamos a examinar la lista para identificar **duplicados implícitos** del género `hiphop`, es decir, nombres mal escritos o variantes que hacen referencia al mismo género musical.\n",
    "\n",
    "Algunos de los duplicados que encontrarás son:\n",
    "\n",
    "* `hip`  \n",
    "* `hop`  \n",
    "* `hip-hop`  \n",
    "\n",
    "Para solucionarlo, vamos a crear una función llamada `replace_wrong_genres()` que tendrá dos parámetros:\n",
    "\n",
    "* `wrong_genres`: una lista con todos los valores que deben ser reemplazados.  \n",
    "* `correct_genre`: un string que se utilizará como valor de reemplazo.\n",
    "\n",
    "El objetivo de esta función es **corregir los valores en la columna `'genre'` del DataFrame `df`**, reemplazando cada valor de la lista `wrong_genres` por `correct_genre`.\n",
    "\n",
    "1. Define una función llamada `replace_wrong_genres()` que reciba dos parámetros: `wrong_genres` y `correct_genre`.\n",
    "\n",
    "2. Dentro de la función, utiliza un bucle `for` para iterar sobre cada valor en la lista `wrong_genres`.\n",
    "\n",
    "3. En cada iteración, accede a la columna `'genre'` del DataFrame `df` y utiliza el método `.replace()` para sustituir el valor incorrecto por `correct_genre`.\n",
    "\n",
    "4. Llama a la función y pasa como argumentos:\n",
    "   - Una lista con los duplicados implícitos: `['hip', 'hop', 'hip-hop']`\n",
    "   - El string de reemplazo: `'hiphop'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "931efc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para reemplazar los duplicados implícitos\n",
    "\n",
    "def replace_wrong_genres(wrong_genres, correct_genre):\n",
    "    for wrong_genre in wrong_genres:\n",
    "        df['genre'] = df['genre'].replace(wrong_genre, correct_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd03aff",
   "metadata": {},
   "source": [
    "Ahora, llama a replace_wrong_genres() y pásale estos argumentos para que retire los duplicados implícitos (hip, hop y hip-hop) y los sustituya por hiphop:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6164f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id                              track            artist  \\\n",
      "0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n",
      "1      55204538        Delayed Because of Accident  Andreas Rönnberg   \n",
      "2        20EC38                  Funiculì funiculà       Mario Lanza   \n",
      "3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n",
      "4      E2DC1FAE                        Soul People        Space Echo   \n",
      "...         ...                                ...               ...   \n",
      "65074  729CBB09                            My Name            McLean   \n",
      "65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n",
      "65076  C5E3A0D5                          Jalopiina           unknown   \n",
      "65077  321D0506                      Freight Train     Chas McDevitt   \n",
      "65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n",
      "\n",
      "            genre         city      time        day  \n",
      "0            rock  Shelbyville  20:28:33  Wednesday  \n",
      "1            rock  Springfield  14:07:09     Friday  \n",
      "2             pop  Shelbyville  20:58:07  Wednesday  \n",
      "3            folk  Shelbyville  08:37:09     Monday  \n",
      "4           dance  Springfield  08:34:34     Monday  \n",
      "...           ...          ...       ...        ...  \n",
      "65074         rnb  Springfield  13:32:28  Wednesday  \n",
      "65075      hiphop  Shelbyville  10:00:00     Monday  \n",
      "65076  industrial  Springfield  20:09:26     Friday  \n",
      "65077        rock  Springfield  21:43:59     Friday  \n",
      "65078     country  Springfield  21:59:46     Friday  \n",
      "\n",
      "[65079 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Elimina los duplicados implícitos\n",
    "# Lista de géneros incorrectos\n",
    "wrong_genres = ['hip', 'hop', 'hip-hop']\n",
    "# Género correcto\n",
    "correct_genre = 'hiphop'\n",
    "\n",
    "# Llamada a la función\n",
    "replace_wrong_genres(wrong_genres, correct_genre)\n",
    "\n",
    "# Para verificar los cambios, puedes imprimir el DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f6dc986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock' nan 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n",
      " 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n",
      " 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n",
      " 'rusrock' 'dnb' 'türk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'drum' 'extrememetal' 'türkçe' 'experimental' 'easy'\n",
      " 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n",
      " 'stonerrock' 'industrial' 'funk' 'middle' 'variété' 'other' 'adult'\n",
      " 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n",
      " 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n",
      " 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n",
      " 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n",
      " 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n",
      " 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n",
      " 'africa' 'audiobook' 'jewish' 'sängerportrait' 'deutschrock' 'eastern'\n",
      " 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n",
      " 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n",
      " 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n",
      " 'brazilian' 'ïîï' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n",
      " 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n",
      " 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n",
      " 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n",
      " 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n",
      " 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n",
      " 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n",
      " 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n",
      " 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n",
      " 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n",
      " 'synthpop' 'rave' 'französisch' 'quebecois' 'speech' 'soulful' 'jam'\n",
      " 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n",
      " 'axé' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forró' 'dirty'\n",
      " 'regional']\n"
     ]
    }
   ],
   "source": [
    "# Comprueba de nuevo los duplicados implícitos\n",
    "# Eliminar duplicados en la columna 'genre'\n",
    "df['genre'] = df['genre'].drop_duplicates()\n",
    "\n",
    "# Mostrar la lista de valores únicos\n",
    "valores_unicos = df['genre'].unique()\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8ab3b",
   "metadata": {},
   "source": [
    "Etapa 2.14. Descríbelo aquí.\n",
    "\n",
    "Al analizar los datos proporcionados, se identificaron varios problemas clave que afectaban la calidad del análisis. En primer lugar, se observó una falta de consistencia en la recopilación de datos, lo que generaba discrepancias en los resultados\n",
    "Además, se detectó que algunos datos estaban incompletos o presentaban errores. Para abordar esta situación, se llevó a cabo un proceso de limpieza de datos, donde se identificaron y corrigieron los errores, así como se completaron los registros faltantes mediante técnicas de imputación.\n",
    "\n",
    "Estas acciones no solo mejoraron la precisión de los datos, sino que también aumentaron la confianza en los resultados del análisis. Al contar con datos más consistentes y precisos, se logró una interpretación más clara y fundamentada, lo que a su vez permitió tomar decisiones más informadas y efectivas. En resumen, la estandarización y limpieza de datos fueron fundamentales para elevar la calidad del análisis y optimizar los resultados obtenidos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9142eb6",
   "metadata": {},
   "source": [
    "## Etapa 3. Prueba de la hipótesis\n",
    "\n",
    "La hipótesis que queremos probar plantea que existen diferencias en la forma en que los usuarios de Springfield y Shelbyville consumen música.\n",
    "Para analizar esto, nos enfocaremos en los datos correspondientes a tres días específicos de la semana: lunes, miércoles y viernes.\n",
    "\n",
    "El análisis consistirá en comparar la cantidad de canciones reproducidas por los usuarios de cada ciudad en esos días. Esto nos permitirá observar posibles patrones o diferencias en los hábitos de consumo entre Springfield y Shelbyville.\n",
    "\n",
    "Para llevar a cabo este análisis, es importante seguir el enfoque de dividir-aplicar-combinar, del que ya hablamos en la lección. En este caso:\n",
    "\n",
    "*  Dividir: separamos los datos en grupos según la ciudad.\n",
    "\n",
    "*  Aplicar: dentro de cada grupo, contamos cuántas canciones se reprodujeron.\n",
    "\n",
    "*  Combinar: reunimos los resultados en una estructura que nos permita comparar fácilmente ambas ciudades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03f11090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n",
      "Shelbyville    19719\n",
      "Springfield    45360\n",
      "Name: track, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cuenta las canciones reproducidas en cada ciudad\n",
    "conteo = df[df['city'].isin(['Shelbyville', 'Springfield'])].groupby(by='city')['track'].count()\n",
    "print(conteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac621dd",
   "metadata": {},
   "source": [
    "`Redacta brevemente tus observaciones sobre los resultados. ¿Qué diferencias notaste entre Springfield y Shelbyville? ¿A qué podrían deberse esas diferencias?`\n",
    "\n",
    "En springfield se reprodujeron mas canciones que en Shelbyville. Mayor poblacion en Sprinfield, mayor numero de personas que escuchan musica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ef81d6",
   "metadata": {},
   "source": [
    "Agrupa los datos por día de la semana y cuenta cuántas canciones se reprodujeron los lunes, miércoles y viernes.\n",
    "\n",
    "Utiliza el mismo método de conteo que antes, pero ahora cambia la columna de agrupación para enfocarte en el día.\n",
    "\n",
    "Esto te permitirá identificar posibles patrones de escucha según el día de la semana.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d2b7506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city         day      \n",
      "Shelbyville  Friday        6259\n",
      "             Monday        5982\n",
      "             Wednesday     7478\n",
      "Springfield  Friday       16890\n",
      "             Monday       16715\n",
      "             Wednesday    11755\n",
      "Name: track, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filtrar por ciudad y días de interés\n",
    "dias_interesados = ['Monday', 'Wednesday', 'Friday']\n",
    "conteo = df[(df['city'\n",
    "].isin(['Shelbyville', 'Springfield'])) & (df['day'].isin(dias_interesados))]\n",
    "\n",
    "# Agrupar por ciudad y día, y contar las canciones\n",
    "conteo_final = conteo.groupby(['city'\n",
    ", 'day'])['track'].count()\n",
    "\n",
    "# Imprimir el conteo\n",
    "print(conteo_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e797f3",
   "metadata": {},
   "source": [
    "`Describe brevemente qué observaste al comparar los lunes, miércoles y viernes. ¿Hubo algún día con menos actividad? ¿Cambian las conclusiones si analizas cada ciudad por separado?`\n",
    "\n",
    "En Springfield el dia que menos se escucha musica es en miercoles mientras que en Shelbyville el dia que menos se escucha musica es en lunes. En Sprinfield se reproducen mas canciones que en Shelbyville"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bb0e8",
   "metadata": {},
   "source": [
    "Hasta ahora has aprendido a contar entradas agrupándolas por un solo criterio, como la ciudad o el día de la semana. Ahora vamos a dar un paso más: necesitas crear una función que **cuente cuántas canciones se reprodujeron en una ciudad específica durante un día determinado**, combinando ambos criterios de filtrado.\n",
    "\n",
    "La función se llamará `number_tracks()` y debe aceptar dos parámetros:\n",
    "\n",
    "- `day`: un día de la semana (por ejemplo, `'Monday'`).\n",
    "- `city`: el nombre de una ciudad (por ejemplo, `'Springfield'`).\n",
    "\n",
    "Dentro de la función, deberás aplicar un **filtrado secuencial mediante indexación lógica**: primero tendrás que filtrar el DataFrame por el día, y luego por la ciudad. Una vez que tengas el subconjunto de datos correcto, debes contar cuántas veces aparece un valor en la columna `'user_id'`. Ese número representará el total de canciones reproducidas bajo esos dos criterios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598d65f",
   "metadata": {},
   "source": [
    "1. Declara una función llamada `number_tracks()` con dos parámetros: `day` y `city`.\n",
    "\n",
    "2. Filtra el DataFrame para conservar solo las filas donde la columna `'day'` sea igual al valor del parámetro `day`.\n",
    "\n",
    "3. A partir del resultado anterior, filtra nuevamente para conservar solo las filas donde la columna `'city'` sea igual al valor del parámetro `city`.\n",
    "\n",
    "4. Extrae la columna `'user_id'` del DataFrame filtrado y utiliza el método `.count()` para contar el número de entradas.\n",
    "\n",
    "5. Guarda ese valor en una variable y **devuélvelo** como resultado de la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b05daee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de canciones reproducidas en Springfield el lunes: 16715\n",
      "Número de canciones reproducidas en Springfield el miércoles: 11755\n",
      "Número de canciones reproducidas en Shelbyville el miércoles: 7478\n",
      "Número de canciones reproducidas en Springfield el viernes: 16890\n",
      "Número de canciones reproducidas en Shelbyville el viernes: 6259\n"
     ]
    }
   ],
   "source": [
    "# Declara la función number_tracks() con dos parámetros: day= y city=.\n",
    "def number_tracks(day, city):\n",
    "    # Almacena las filas del DataFrame donde el valor en la columna 'day' es igual al parámetro day=\n",
    "    filtered_df = df[df['day'] == day]\n",
    "    # Filtra las filas donde el valor en la columna 'city' es igual al parámetro city=\n",
    "    filtered_df = filtered_df[filtered_df['city'] == city]\n",
    "    # Extrae la columna 'user_id' de la tabla filtrada y aplica el método count()\n",
    "    count = filtered_df['user_id'].count()\n",
    "    # Devuelve el número de valores de la columna 'user_id'\n",
    "    return count\n",
    "\n",
    "# El número de canciones reproducidas en Springfield el lunes\n",
    "springfield_monday = number_tracks('Monday', 'Springfield')\n",
    "print(f'Número de canciones reproducidas en Springfield el lunes: {springfield_monday}')\n",
    "\n",
    "# El número de canciones reproducidas en Springfield el miércoles\n",
    "springfield_wednesday = number_tracks('Wednesday', 'Springfield')\n",
    "print(f'Número de canciones reproducidas en Springfield el miércoles: {springfield_wednesday}')\n",
    "\n",
    "# El número de canciones reproducidas en Shelbyville el miércoles\n",
    "shelbyville_wednesday = number_tracks('Wednesday', 'Shelbyville')\n",
    "print(f'Número de canciones reproducidas en Shelbyville el miércoles: {shelbyville_wednesday}')\n",
    "\n",
    "# El número de canciones reproducidas en Springfield el viernes\n",
    "springfield_friday = number_tracks('Friday', 'Springfield')\n",
    "print(f'Número de canciones reproducidas en Springfield el viernes: {springfield_friday}')\n",
    "\n",
    "# El número de canciones reproducidas en Shelbyville el viernes\n",
    "shelbyville_friday = number_tracks('Friday', 'Shelbyville')\n",
    "print(f'Número de canciones reproducidas en Shelbyville el viernes: {shelbyville_friday}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93403231",
   "metadata": {},
   "source": [
    "## Escribe tus conclusiones finales sobre la hipótesis.\n",
    " * ¿Los datos apoyan la idea de que el comportamiento de los usuarios respecto a la música que escuchan varía según la ciudad y el día de la semana?\n",
    " * Indica si la hipótesis debe aceptarse o rechazarse, y justifica tu respuesta con base en los resultados obtenidos.\n",
    "\n",
    " Los datos claramente nos indican que el comportamiento de los usuarios cambia segun la cuidad y dia de la semana. Ejemplo en Springfield se escucha mas musica que en Shelbyville caulquier dia de la semana."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
